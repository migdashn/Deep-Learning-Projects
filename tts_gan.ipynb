{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/migdashn/Deep-Learning-Projects/blob/main/tts_gan.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install einops"
      ],
      "metadata": {
        "id": "UaLQnNzIlidG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Imports"
      ],
      "metadata": {
        "id": "3DsS1a3WmlW2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ZfL5UN8QiB7h"
      },
      "outputs": [],
      "source": [
        "from numpy.random import rand\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.layers.core.activation import Activation\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "from keras.utils.vis_utils import plot_model\n",
        "\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch import Tensor\n",
        "import math\n",
        "import numpy as np\n",
        "\n",
        "from torchvision.transforms import Compose, Resize, ToTensor\n",
        "from einops import rearrange, reduce, repeat\n",
        "from einops.layers.torch import Rearrange, Reduce\n",
        "from torchsummary import summary\n",
        "from matplotlib import pyplot"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "BVyVg7LImCbh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Generator Class"
      ],
      "metadata": {
        "id": "xEdiymr5mfEM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Generator(nn.module):\n",
        "    def __init__(self, seq_len=150, channels=3, num_classes=9, latent_dim=100, data_embed_dim=10, \n",
        "                label_embed_dim=10 ,depth=3, num_heads=5, \n",
        "                forward_drop_rate=0.5, attn_drop_rate=0.5):\n",
        "        super(Generator, self).__init__()\n",
        "        self.seq_len = seq_len\n",
        "        self.channels = channels\n",
        "        self.num_classes = num_classes\n",
        "        self.latent_dim = latent_dim\n",
        "        self.data_embed_dim = data_embed_dim\n",
        "        self.label_embed_dim = label_embed_dim\n",
        "        self.depth = depth\n",
        "        self.num_heads = num_heads\n",
        "        self.attn_drop_rate = attn_drop_rate\n",
        "        self.forward_drop_rate = forward_drop_rate  \n",
        "        self.l1 = nn.Linear(self.latent_dim + self.label_embed_dim, self.seq_len * self.data_embed_dim)\n",
        "        self.label_embedding = nn.Embedding(self.num_classes, self.label_embed_dim) \n",
        "        self.blocks = Gen_TransformerEncoder(depth=self.depth,emb_size = self.data_embed_dim,\n",
        "                 num_heads = self.num_heads, drop_p = self.attn_drop_rate, forward_drop_p=self.forward_drop_rate)\n",
        "        self.deconv = nn.Sequential(nn.Conv2d(self.data_embed_dim, self.channels, 1, 1, 0))\n",
        "\n",
        "\n",
        "    def forward(self, z, labels):\n",
        "        c = self.label_embedding(labels)\n",
        "        x = torch.cat([z, c], 1)\n",
        "        x = self.l1(x)\n",
        "        x = x.view(-1, self.seq_len, self.data_embed_dim)\n",
        "        H, W = 1, self.seq_len\n",
        "        x = self.blocks(x)\n",
        "        x = x.reshape(x.shape[0], 1, x.shape[1], x.shape[2])\n",
        "        output = self.deconv(x.permute(0, 3, 1, 2))\n",
        "        return output \n"
      ],
      "metadata": {
        "id": "ZWpO-cF7jGzG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Disciminator Class"
      ],
      "metadata": {
        "id": "V8iXucW5mvmx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Discriminator(nn.Sequential):\n",
        "    def __init__(self, \n",
        "                 in_channels=3,\n",
        "                 patch_size=15,\n",
        "                 data_emb_size=50,\n",
        "                 label_emb_size=10,\n",
        "                 seq_length = 150,\n",
        "                 depth=3, \n",
        "                 n_classes=9, \n",
        "                 **kwargs):\n",
        "        super().__init__(\n",
        "            PatchEmbedding_Linear(in_channels, patch_size, data_emb_size, seq_length),\n",
        "            Dis_TransformerEncoder(depth, emb_size=data_emb_size, drop_p=0.5, forward_drop_p=0.5, **kwargs),\n",
        "            ClassificationHead(data_emb_size, 1, n_classes)\n",
        "        )"
      ],
      "metadata": {
        "id": "2GKTMC50mebF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Encoder Block"
      ],
      "metadata": {
        "id": "OMdpKevTnKMZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Gen_TransformerEncoderBlock(nn.Sequential):\n",
        "    def __init__(self,emb_size,num_heads=5,drop_p=0.5,\n",
        "                 forward_expansion=4, forward_drop_p=0.5):\n",
        "        super().__init__(\n",
        "            ResidualAdd(nn.Sequential(nn.LayerNorm(emb_size),\n",
        "                MultiHeadAttention(emb_size, num_heads, drop_p), nn.Dropout(drop_p))),\n",
        "            ResidualAdd(nn.Sequential(nn.LayerNorm(emb_size),\n",
        "            FeedForwardBlock(emb_size, expansion=forward_expansion, drop_p=forward_drop_p),\n",
        "            nn.Dropout(drop_p))))\n",
        "\n",
        "\n",
        "class Gen_TransformerEncoder(nn.Sequential):\n",
        "    def __init__(self, depth=8, **kwargs):\n",
        "        super().__init__(*[Gen_TransformerEncoderBlock(**kwargs) for _ in range(depth)]) \n"
      ],
      "metadata": {
        "id": "B9Rb2IHXnJXH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Dis_TransformerEncoderBlock(nn.Sequential):\n",
        "    def __init__(self,\n",
        "                 emb_size=100,\n",
        "                 num_heads=5,\n",
        "                 drop_p=0.,\n",
        "                 forward_expansion=4,\n",
        "                 forward_drop_p=0.):\n",
        "      \n",
        "        super().__init__(\n",
        "            ResidualAdd(nn.Sequential(nn.LayerNorm(emb_size),\n",
        "                MultiHeadAttention(emb_size, num_heads, drop_p),\n",
        "                nn.Dropout(drop_p))),\n",
        "            ResidualAdd(nn.Sequential(nn.LayerNorm(emb_size),\n",
        "                FeedForwardBlock(emb_size, expansion=forward_expansion, drop_p=forward_drop_p),\n",
        "                nn.Dropout(drop_p))))\n",
        "\n",
        "\n",
        "class Dis_TransformerEncoder(nn.Sequential):\n",
        "    def __init__(self, depth=8, **kwargs):\n",
        "        super().__init__(*[Dis_TransformerEncoderBlock(**kwargs) for _ in range(depth)])"
      ],
      "metadata": {
        "id": "FHCCfUFpootk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class MultiHeadAttention(nn.Module):\n",
        "    def __init__(self, emb_size, num_heads, dropout):\n",
        "        super().__init__()\n",
        "        self.emb_size = emb_size\n",
        "        self.num_heads = num_heads\n",
        "        self.keys = nn.Linear(emb_size, emb_size)\n",
        "        self.queries = nn.Linear(emb_size, emb_size)\n",
        "        self.values = nn.Linear(emb_size, emb_size)\n",
        "        self.att_drop = nn.Dropout(dropout)\n",
        "        self.projection = nn.Linear(emb_size, emb_size)\n",
        "\n",
        "    def forward(self, x: Tensor, mask: Tensor = None) -> Tensor:\n",
        "        queries = rearrange(self.queries(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
        "        keys = rearrange(self.keys(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
        "        values = rearrange(self.values(x), \"b n (h d) -> b h n d\", h=self.num_heads)\n",
        "        energy = torch.einsum('bhqd, bhkd -> bhqk', queries, keys)  # batch, num_heads, query_len, key_len\n",
        "        if mask is not None:\n",
        "            fill_value = torch.finfo(torch.float32).min\n",
        "            energy.mask_fill(~mask, fill_value)\n",
        "\n",
        "        scaling = self.emb_size ** (1 / 2)\n",
        "        att = F.softmax(energy / scaling, dim=-1)\n",
        "        att = self.att_drop(att)\n",
        "        out = torch.einsum('bhal, bhlv -> bhav ', att, values)\n",
        "        out = rearrange(out, \"b h n d -> b n (h d)\")\n",
        "        out = self.projection(out)\n",
        "        return out\n",
        "\n",
        "\n",
        "class ClassificationHead(nn.Sequential):\n",
        "    def __init__(self, emb_size=100, adv_classes=2, cls_classes=10):\n",
        "        super().__init__()\n",
        "        self.adv_head = nn.Sequential(\n",
        "            Reduce('b n e -> b e', reduction='mean'),\n",
        "            nn.LayerNorm(emb_size),\n",
        "            nn.Linear(emb_size, adv_classes)\n",
        "        )\n",
        "        self.cls_head = nn.Sequential(\n",
        "            Reduce('b n e -> b e', reduction='mean'),\n",
        "            nn.LayerNorm(emb_size),\n",
        "            nn.Linear(emb_size, cls_classes)\n",
        "        )\n",
        "\n",
        "    def forward(self, x):\n",
        "        out_adv = self.adv_head(x)\n",
        "        out_cls = self.cls_head(x)\n",
        "        return out_adv, out_cls\n"
      ],
      "metadata": {
        "id": "sqAXZo24m4Af"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class ResidualAdd(nn.Module):\n",
        "    def __init__(self, fn):\n",
        "        super().__init__()\n",
        "        self.fn = fn\n",
        "\n",
        "    def forward(self, x, **kwargs):\n",
        "        res = x\n",
        "        x = self.fn(x, **kwargs)\n",
        "        x += res\n",
        "        return x\n",
        "    \n",
        "    \n",
        "class FeedForwardBlock(nn.Sequential):\n",
        "    def __init__(self, emb_size, expansion, drop_p):\n",
        "        super().__init__(\n",
        "            nn.Linear(emb_size, expansion * emb_size),\n",
        "            nn.GELU(),\n",
        "            nn.Dropout(drop_p),\n",
        "            nn.Linear(expansion * emb_size, emb_size),\n",
        "        )\n",
        "\n",
        "\n",
        "class PatchEmbedding_Linear(nn.Module):\n",
        "    def __init__(self, in_channels = 21, patch_size = 16, emb_size = 100, seq_length = 1024):\n",
        "        super().__init__()\n",
        "        #change the conv2d parameters here\n",
        "        self.projection = nn.Sequential(\n",
        "            Rearrange('b c (h s1) (w s2) -> b (h w) (s1 s2 c)',s1 = 1, s2 = patch_size),\n",
        "            nn.Linear(patch_size*in_channels, emb_size)\n",
        "        )\n",
        "        self.cls_token = nn.Parameter(torch.randn(1, 1, emb_size))\n",
        "        self.positions = nn.Parameter(torch.randn((seq_length // patch_size) + 1, emb_size))\n",
        "\n",
        "\n",
        "    def forward(self, x:Tensor) ->Tensor:\n",
        "        b, _, _, _ = x.shape\n",
        "        x = self.projection(x)\n",
        "        cls_tokens = repeat(self.cls_token, '() n e -> b n e', b=b)\n",
        "        #prepend the cls token to the input\n",
        "        x = torch.cat([cls_tokens, x], dim=1)\n",
        "        # position\n",
        "        x += self.positions\n",
        "        return x   "
      ],
      "metadata": {
        "id": "ilsQr8pRoMZN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def cur_stages(iter, args):\n",
        "        \"\"\"\n",
        "        Return current stage.\n",
        "        :param epoch: current epoch.\n",
        "        :return: current stage\n",
        "        \"\"\"\n",
        "        idx = 0\n",
        "        for i in range(len(args.grow_steps)):\n",
        "            if iter >= args.grow_steps[i]:\n",
        "                idx = i+1\n",
        "        return idx\n",
        "\n",
        "def compute_gradient_penalty(D, real_samples, fake_samples, phi):\n",
        "    \"\"\"Calculates the gradient penalty loss for WGAN GP\"\"\"\n",
        "    # Random weight term for interpolation between real and fake samples\n",
        "    alpha = torch.Tensor(np.random.random((real_samples.size(0), 1, 1, 1))).to(real_samples.get_device())\n",
        "    # Get random interpolation between real and fake samples\n",
        "    interpolates = (alpha * real_samples + ((1 - alpha) * fake_samples)).requires_grad_(True)\n",
        "    d_interpolates = D(interpolates)\n",
        "    fake = torch.ones([real_samples.shape[0], 1], requires_grad=False).to(real_samples.get_device())\n",
        "    # Get gradient w.r.t. interpolates\n",
        "    gradients = torch.autograd.grad(\n",
        "        outputs=d_interpolates,\n",
        "        inputs=interpolates,\n",
        "        grad_outputs=fake,\n",
        "        create_graph=True,\n",
        "        retain_graph=True,\n",
        "        only_inputs=True,\n",
        "    )[0]\n",
        "    gradients = gradients.reshape(gradients.size(0), -1)\n",
        "    gradient_penalty = ((gradients.norm(2, dim=1) - phi) ** 2).mean()\n",
        "    return gradient_penalty\n",
        "\n",
        "\n",
        "def train_d(args, gen_net: nn.Module, dis_net: nn.Module, dis_optimizer, train_loader, epoch, writer_dict,fixed_z, schedulers=None):\n",
        "    writer = writer_dict['writer']\n",
        "    dis_net.train()\n",
        "    \n",
        "    dis_optimizer.zero_grad()\n",
        "    \n",
        "    for iter_idx, (imgs, _) in enumerate(tqdm(train_loader)):\n",
        "        global_steps = writer_dict['train_global_steps']\n",
        "        \n",
        "\n",
        "        # Adversarial ground truths\n",
        "        real_imgs = imgs.type(torch.cuda.FloatTensor).cuda(args.gpu, non_blocking=True)\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = torch.cuda.FloatTensor(np.random.normal(0, 1, (imgs.shape[0], args.latent_dim))).cuda(args.gpu, non_blocking=True)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "        \n",
        "\n",
        "        real_validity = dis_net(real_imgs)\n",
        "        fake_imgs = gen_net(z).detach()\n",
        "        \n",
        "        assert fake_imgs.size() == real_imgs.size(), f\"fake_imgs.size(): {fake_imgs.size()} real_imgs.size(): {real_imgs.size()}\"\n",
        "\n",
        "        fake_validity = dis_net(fake_imgs)\n",
        "\n",
        "        # cal loss\n",
        "        if args.loss == 'hinge':\n",
        "            d_loss = 0\n",
        "            d_loss = torch.mean(nn.ReLU(inplace=True)(1.0 - real_validity)) + \\\n",
        "                    torch.mean(nn.ReLU(inplace=True)(1 + fake_validity))\n",
        "        elif args.loss == 'standard':\n",
        "            #soft label\n",
        "            real_label = torch.full((imgs.shape[0],), 0.9, dtype=torch.float, device=real_imgs.get_device())\n",
        "            fake_label = torch.full((imgs.shape[0],), 0.1, dtype=torch.float, device=real_imgs.get_device())\n",
        "            real_validity = nn.Sigmoid()(real_validity.view(-1))\n",
        "            fake_validity = nn.Sigmoid()(fake_validity.view(-1))\n",
        "            d_real_loss = nn.BCELoss()(real_validity, real_label)\n",
        "            d_fake_loss = nn.BCELoss()(fake_validity, fake_label)\n",
        "            d_loss = d_real_loss + d_fake_loss\n",
        "        elif args.loss == 'lsgan':\n",
        "            if isinstance(fake_validity, list):\n",
        "                d_loss = 0\n",
        "                for real_validity_item, fake_validity_item in zip(real_validity, fake_validity):\n",
        "                    real_label = torch.full((real_validity_item.shape[0],real_validity_item.shape[1]), 1., dtype=torch.float, device=real_imgs.get_device())\n",
        "                    fake_label = torch.full((real_validity_item.shape[0],real_validity_item.shape[1]), 0., dtype=torch.float, device=real_imgs.get_device())\n",
        "                    d_real_loss = nn.MSELoss()(real_validity_item, real_label)\n",
        "                    d_fake_loss = nn.MSELoss()(fake_validity_item, fake_label)\n",
        "                    d_loss += d_real_loss + d_fake_loss\n",
        "            else:\n",
        "                real_label = torch.full((real_validity.shape[0],real_validity.shape[1]), 1., dtype=torch.float, device=real_imgs.get_device())\n",
        "                fake_label = torch.full((real_validity.shape[0],real_validity.shape[1]), 0., dtype=torch.float, device=real_imgs.get_device())\n",
        "                d_real_loss = nn.MSELoss()(real_validity, real_label)\n",
        "                d_fake_loss = nn.MSELoss()(fake_validity, fake_label)\n",
        "                d_loss = d_real_loss + d_fake_loss\n",
        "        elif args.loss == 'wgangp':\n",
        "            gradient_penalty = compute_gradient_penalty(dis_net, real_imgs, fake_imgs.detach(), args.phi)\n",
        "            d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + gradient_penalty * 10 / (\n",
        "                    args.phi ** 2)\n",
        "        elif args.loss == 'wgangp-mode':\n",
        "            gradient_penalty = compute_gradient_penalty(dis_net, real_imgs, fake_imgs.detach(), args.phi)\n",
        "            d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + gradient_penalty * 10 / (\n",
        "                    args.phi ** 2)\n",
        "        elif args.loss == 'wgangp-eps':\n",
        "            gradient_penalty = compute_gradient_penalty(dis_net, real_imgs, fake_imgs.detach(), args.phi)\n",
        "            d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + gradient_penalty * 10 / (\n",
        "                    args.phi ** 2)\n",
        "            d_loss += (torch.mean(real_validity) ** 2) * 1e-3\n",
        "        else:\n",
        "            raise NotImplementedError(args.loss)\n",
        "        d_loss = d_loss/float(args.accumulated_times)\n",
        "        d_loss.backward()\n",
        "        \n",
        "        if (iter_idx + 1) % args.accumulated_times == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(dis_net.parameters(), 5.)\n",
        "            dis_optimizer.step()\n",
        "            dis_optimizer.zero_grad()\n",
        "\n",
        "            writer.add_scalar('d_loss', d_loss.item(), global_steps) if args.rank == 0 else 0\n",
        "\n",
        "        tqdm.write( \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f]\" %\n",
        "        (epoch, args.max_epoch, iter_idx % len(train_loader), len(train_loader), d_loss.item()))\n",
        "    \n",
        "        writer_dict['train_global_steps'] = global_steps + 1 \n",
        "\n",
        "\n",
        "def train(args, gen_net: nn.Module, dis_net: nn.Module, gen_optimizer, dis_optimizer, gen_avg_param, train_loader,\n",
        "          epoch, writer_dict, fixed_z, schedulers=None):\n",
        "    writer = writer_dict['writer']\n",
        "    gen_step = 0\n",
        "    # train mode\n",
        "    gen_net.train()\n",
        "    dis_net.train()\n",
        "    \n",
        "    dis_optimizer.zero_grad()\n",
        "    gen_optimizer.zero_grad()\n",
        "    for iter_idx, (imgs, _) in enumerate(tqdm(train_loader)):\n",
        "        global_steps = writer_dict['train_global_steps']\n",
        "        \n",
        "\n",
        "        # Adversarial ground truths\n",
        "        real_imgs = imgs.type(torch.cuda.FloatTensor).cuda(args.gpu, non_blocking=True)\n",
        "\n",
        "        # Sample noise as generator input\n",
        "        z = torch.cuda.FloatTensor(np.random.normal(0, 1, (imgs.shape[0], args.latent_dim))).cuda(args.gpu, non_blocking=True)\n",
        "\n",
        "        # ---------------------\n",
        "        #  Train Discriminator\n",
        "        # ---------------------\n",
        "        \n",
        "\n",
        "        real_validity = dis_net(real_imgs)\n",
        "        fake_imgs = gen_net(z).detach()\n",
        "        \n",
        "        assert fake_imgs.size() == real_imgs.size(), f\"fake_imgs.size(): {fake_imgs.size()} real_imgs.size(): {real_imgs.size()}\"\n",
        "\n",
        "        fake_validity = dis_net(fake_imgs)\n",
        "\n",
        "        # cal loss\n",
        "        if args.loss == 'hinge':\n",
        "            d_loss = 0\n",
        "            d_loss = torch.mean(nn.ReLU(inplace=True)(1.0 - real_validity)) + \\\n",
        "                    torch.mean(nn.ReLU(inplace=True)(1 + fake_validity))\n",
        "        elif args.loss == 'standard':\n",
        "            #soft label\n",
        "            real_label = torch.full((imgs.shape[0],), 0.9, dtype=torch.float, device=real_imgs.get_device())\n",
        "            fake_label = torch.full((imgs.shape[0],), 0.1, dtype=torch.float, device=real_imgs.get_device())\n",
        "            real_validity = nn.Sigmoid()(real_validity.view(-1))\n",
        "            fake_validity = nn.Sigmoid()(fake_validity.view(-1))\n",
        "            d_real_loss = nn.BCELoss()(real_validity, real_label)\n",
        "            d_fake_loss = nn.BCELoss()(fake_validity, fake_label)\n",
        "            d_loss = d_real_loss + d_fake_loss\n",
        "        elif args.loss == 'lsgan':\n",
        "            if isinstance(fake_validity, list):\n",
        "                d_loss = 0\n",
        "                for real_validity_item, fake_validity_item in zip(real_validity, fake_validity):\n",
        "                    real_label = torch.full((real_validity_item.shape[0],real_validity_item.shape[1]), 1., dtype=torch.float, device=real_imgs.get_device())\n",
        "                    fake_label = torch.full((real_validity_item.shape[0],real_validity_item.shape[1]), 0., dtype=torch.float, device=real_imgs.get_device())\n",
        "                    d_real_loss = nn.MSELoss()(real_validity_item, real_label)\n",
        "                    d_fake_loss = nn.MSELoss()(fake_validity_item, fake_label)\n",
        "                    d_loss += d_real_loss + d_fake_loss\n",
        "            else:\n",
        "                real_label = torch.full((real_validity.shape[0],real_validity.shape[1]), 1., dtype=torch.float, device=real_imgs.get_device())\n",
        "                fake_label = torch.full((real_validity.shape[0],real_validity.shape[1]), 0., dtype=torch.float, device=real_imgs.get_device())\n",
        "                d_real_loss = nn.MSELoss()(real_validity, real_label)\n",
        "                d_fake_loss = nn.MSELoss()(fake_validity, fake_label)\n",
        "                d_loss = d_real_loss + d_fake_loss\n",
        "        elif args.loss == 'wgangp':\n",
        "            gradient_penalty = compute_gradient_penalty(dis_net, real_imgs, fake_imgs.detach(), args.phi)\n",
        "            d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + gradient_penalty * 10 / (\n",
        "                    args.phi ** 2)\n",
        "        elif args.loss == 'wgangp-mode':\n",
        "            gradient_penalty = compute_gradient_penalty(dis_net, real_imgs, fake_imgs.detach(), args.phi)\n",
        "            d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + gradient_penalty * 10 / (\n",
        "                    args.phi ** 2)\n",
        "        elif args.loss == 'wgangp-eps':\n",
        "            gradient_penalty = compute_gradient_penalty(dis_net, real_imgs, fake_imgs.detach(), args.phi)\n",
        "            d_loss = -torch.mean(real_validity) + torch.mean(fake_validity) + gradient_penalty * 10 / (\n",
        "                    args.phi ** 2)\n",
        "            d_loss += (torch.mean(real_validity) ** 2) * 1e-3\n",
        "        else:\n",
        "            raise NotImplementedError(args.loss)\n",
        "        d_loss = d_loss/float(args.accumulated_times)\n",
        "        d_loss.backward()\n",
        "        \n",
        "        if (iter_idx + 1) % args.accumulated_times == 0:\n",
        "            torch.nn.utils.clip_grad_norm_(dis_net.parameters(), 5.)\n",
        "            dis_optimizer.step()\n",
        "            dis_optimizer.zero_grad()\n",
        "\n",
        "            writer.add_scalar('d_loss', d_loss.item(), global_steps) if args.rank == 0 else 0\n",
        "\n",
        "        # -----------------\n",
        "        #  Train Generator\n",
        "        # -----------------\n",
        "        if global_steps % (args.n_critic * args.accumulated_times) == 0:\n",
        "            \n",
        "            for accumulated_idx in range(args.g_accumulated_times):\n",
        "                gen_z = torch.cuda.FloatTensor(np.random.normal(0, 1, (args.gen_batch_size, args.latent_dim)))\n",
        "                gen_imgs = gen_net(gen_z)\n",
        "                fake_validity = dis_net(gen_imgs)\n",
        "\n",
        "                # cal loss\n",
        "                loss_lz = torch.tensor(0)\n",
        "                if args.loss == \"standard\":\n",
        "                    real_label = torch.full((args.gen_batch_size,), 1., dtype=torch.float, device=real_imgs.get_device())\n",
        "                    fake_validity = nn.Sigmoid()(fake_validity.view(-1))\n",
        "                    g_loss = nn.BCELoss()(fake_validity.view(-1), real_label)\n",
        "                if args.loss == \"lsgan\":\n",
        "                    if isinstance(fake_validity, list):\n",
        "                        g_loss = 0\n",
        "                        for fake_validity_item in fake_validity:\n",
        "                            real_label = torch.full((fake_validity_item.shape[0],fake_validity_item.shape[1]), 1., dtype=torch.float, device=real_imgs.get_device())\n",
        "                            g_loss += nn.MSELoss()(fake_validity_item, real_label)\n",
        "                    else:\n",
        "                        real_label = torch.full((fake_validity.shape[0],fake_validity.shape[1]), 1., dtype=torch.float, device=real_imgs.get_device())\n",
        "                        # fake_validity = nn.Sigmoid()(fake_validity.view(-1))\n",
        "                        g_loss = nn.MSELoss()(fake_validity, real_label)\n",
        "                elif args.loss == 'wgangp-mode':\n",
        "                    fake_image1, fake_image2 = gen_imgs[:args.gen_batch_size//2], gen_imgs[args.gen_batch_size//2:]\n",
        "                    z_random1, z_random2 = gen_z[:args.gen_batch_size//2], gen_z[args.gen_batch_size//2:]\n",
        "                    lz = torch.mean(torch.abs(fake_image2 - fake_image1)) / torch.mean(\n",
        "                    torch.abs(z_random2 - z_random1))\n",
        "                    eps = 1 * 1e-5\n",
        "                    loss_lz = 1 / (lz + eps)\n",
        "\n",
        "                    g_loss = -torch.mean(fake_validity) + loss_lz\n",
        "                else:\n",
        "                    g_loss = -torch.mean(fake_validity)\n",
        "                g_loss = g_loss/float(args.g_accumulated_times)\n",
        "                g_loss.backward()\n",
        "            \n",
        "            torch.nn.utils.clip_grad_norm_(gen_net.parameters(), 5.)\n",
        "            gen_optimizer.step()\n",
        "            gen_optimizer.zero_grad()\n",
        "\n",
        "            # adjust learning rate\n",
        "            if schedulers:\n",
        "                gen_scheduler, dis_scheduler = schedulers\n",
        "                g_lr = gen_scheduler.step(global_steps)\n",
        "                d_lr = dis_scheduler.step(global_steps)\n",
        "                writer.add_scalar('LR/g_lr', g_lr, global_steps)\n",
        "                writer.add_scalar('LR/d_lr', d_lr, global_steps)\n",
        "\n",
        "            # moving average weight\n",
        "            ema_nimg = args.ema_kimg * 1000\n",
        "            cur_nimg = args.dis_batch_size * args.world_size * global_steps\n",
        "            if args.ema_warmup != 0:\n",
        "                ema_nimg = min(ema_nimg, cur_nimg * args.ema_warmup)\n",
        "                ema_beta = 0.5 ** (float(args.dis_batch_size * args.world_size) / max(ema_nimg, 1e-8))\n",
        "            else:\n",
        "                ema_beta = args.ema\n",
        "                \n",
        "            # moving average weight\n",
        "            for p, avg_p in zip(gen_net.parameters(), gen_avg_param):\n",
        "                cpu_p = deepcopy(p)\n",
        "                avg_p.mul_(ema_beta).add_(1. - ema_beta, cpu_p.cpu().data)\n",
        "                del cpu_p\n",
        "\n",
        "            writer.add_scalar('g_loss', g_loss.item(), global_steps) if args.rank == 0 else 0\n",
        "            gen_step += 1\n",
        "\n",
        "        # verbose\n",
        "        if gen_step and iter_idx % args.print_freq == 0 and args.rank == 0:\n",
        "            sample_imgs = torch.cat((gen_imgs[:16], real_imgs[:16]), dim=0)\n",
        "#             scale_factor = args.img_size // int(sample_imgs.size(3))\n",
        "#             sample_imgs = torch.nn.functional.interpolate(sample_imgs, scale_factor=2)\n",
        "#             img_grid = make_grid(sample_imgs, nrow=4, normalize=True, scale_each=True)\n",
        "#             save_image(sample_imgs, f'sampled_images_{args.exp_name}.jpg', nrow=4, normalize=True, scale_each=True)\n",
        "            # writer.add_image(f'sampled_images_{args.exp_name}', img_grid, global_steps)\n",
        "            tqdm.write(\n",
        "                \"[Epoch %d/%d] [Batch %d/%d] [D loss: %f] [G loss: %f] [ema: %f] \" %\n",
        "                (epoch, args.max_epoch, iter_idx % len(train_loader), len(train_loader), d_loss.item(), g_loss.item(), ema_beta))\n",
        "            del gen_imgs\n",
        "            del real_imgs\n",
        "            del fake_validity\n",
        "            del real_validity\n",
        "            del g_loss\n",
        "            del d_loss\n",
        "\n",
        "        writer_dict['train_global_steps'] = global_steps + 1 \n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "def get_is(args, gen_net: nn.Module, num_img):\n",
        "    \"\"\"\n",
        "    Get inception score.\n",
        "    :param args:\n",
        "    :param gen_net:\n",
        "    :param num_img:\n",
        "    :return: Inception score\n",
        "    \"\"\"\n",
        "\n",
        "    # eval mode\n",
        "    gen_net = gen_net.eval()\n",
        "\n",
        "    eval_iter = num_img // args.eval_batch_size\n",
        "    img_list = list()\n",
        "    for _ in range(eval_iter):\n",
        "        z = torch.cuda.FloatTensor(np.random.normal(0, 1, (args.eval_batch_size, args.latent_dim)))\n",
        "\n",
        "        # Generate a batch of images\n",
        "        gen_imgs = gen_net(z).mul_(127.5).add_(127.5).clamp_(0.0, 255.0).permute(0, 2, 3, 1).to('cpu',\n",
        "                                                                                                torch.uint8).numpy()\n",
        "        img_list.extend(list(gen_imgs))\n",
        "\n",
        "    # get inception score\n",
        "    logger.info('calculate Inception score...')\n",
        "    mean, std = get_inception_score(img_list)\n",
        "\n",
        "    return mean\n",
        "\n",
        "\n",
        "def validate(args, fixed_z, fid_stat, epoch, gen_net: nn.Module, writer_dict, clean_dir=True):\n",
        "    writer = writer_dict['writer']\n",
        "    global_steps = writer_dict['valid_global_steps']\n",
        "\n",
        "    # eval mode\n",
        "    gen_net.eval()\n",
        "\n",
        "\n",
        "#     get inception score\n",
        "    logger.info('=> calculate inception score') if args.rank == 0 else 0\n",
        "    if args.rank == 0:\n",
        "#         mean, std = get_inception_score(img_list)\n",
        "        mean, std = 0, 0\n",
        "    else:\n",
        "        mean, std = 0, 0\n",
        "    print(f\"Inception score: {mean}\") if args.rank == 0 else 0\n",
        "#     mean, std = 0, 0\n",
        "    # get fid score\n",
        "    print('=> calculate fid score') if args.rank == 0 else 0\n",
        "    if args.rank == 0:\n",
        "        fid_score = get_fid(args, fid_stat, epoch, gen_net, args.num_eval_imgs, args.gen_batch_size, args.eval_batch_size, writer_dict=writer_dict, cls_idx=None)\n",
        "    else:\n",
        "        fid_score = 10000\n",
        "    # fid_score = 10000\n",
        "    print(f\"FID score: {fid_score}\") if args.rank == 0 else 0\n",
        "    \n",
        "    if args.rank == 0:\n",
        "        writer.add_scalar('Inception_score/mean', mean, global_steps)\n",
        "        writer.add_scalar('Inception_score/std', std, global_steps)\n",
        "        writer.add_scalar('FID_score', fid_score, global_steps)\n",
        "\n",
        "        writer_dict['valid_global_steps'] = global_steps + 1\n",
        "\n",
        "    return mean, fid_score\n",
        "\n",
        "\n",
        "def save_samples(args, fixed_z, fid_stat, epoch, gen_net: nn.Module, writer_dict, clean_dir=True):\n",
        "\n",
        "    # eval mode\n",
        "    gen_net.eval()\n",
        "    with torch.no_grad():\n",
        "        # generate images\n",
        "        batch_size = fixed_z.size(0)\n",
        "        sample_imgs = []\n",
        "        for i in range(fixed_z.size(0)):\n",
        "            sample_img = gen_net(fixed_z[i:(i+1)], epoch)\n",
        "            sample_imgs.append(sample_img)\n",
        "        sample_imgs = torch.cat(sample_imgs, dim=0)\n",
        "        os.makedirs(f\"./samples/{args.exp_name}\", exist_ok=True)\n",
        "        save_image(sample_imgs, f'./samples/{args.exp_name}/sampled_images_{epoch}.png', nrow=10, normalize=True, scale_each=True)\n",
        "    return 0\n",
        "\n",
        "\n",
        "def get_topk_arch_hidden(args, controller, gen_net, prev_archs, prev_hiddens):\n",
        "    \"\"\"\n",
        "    ~\n",
        "    :param args:\n",
        "    :param controller:\n",
        "    :param gen_net:\n",
        "    :param prev_archs: previous architecture\n",
        "    :param prev_hiddens: previous hidden vector\n",
        "    :return: a list of topk archs and hiddens.\n",
        "    \"\"\"\n",
        "    logger.info(f'=> get top{args.topk} archs out of {args.num_candidate} candidate archs...')\n",
        "    assert args.num_candidate >= args.topk\n",
        "    controller.eval()\n",
        "    cur_stage = controller.cur_stage\n",
        "    archs, _, _, hiddens = controller.sample(args.num_candidate, with_hidden=True, prev_archs=prev_archs,\n",
        "                                             prev_hiddens=prev_hiddens)\n",
        "    hxs, cxs = hiddens\n",
        "    arch_idx_perf_table = {}\n",
        "    for arch_idx in range(len(archs)):\n",
        "        logger.info(f'arch: {archs[arch_idx]}')\n",
        "        gen_net.set_arch(archs[arch_idx], cur_stage)\n",
        "        is_score = get_is(args, gen_net, args.rl_num_eval_img)\n",
        "        logger.info(f'get Inception score of {is_score}')\n",
        "        arch_idx_perf_table[arch_idx] = is_score\n",
        "    topk_arch_idx_perf = sorted(arch_idx_perf_table.items(), key=operator.itemgetter(1))[::-1][:args.topk]\n",
        "    topk_archs = []\n",
        "    topk_hxs = []\n",
        "    topk_cxs = []\n",
        "    logger.info(f'top{args.topk} archs:')\n",
        "    for arch_idx_perf in topk_arch_idx_perf:\n",
        "        logger.info(arch_idx_perf)\n",
        "        arch_idx = arch_idx_perf[0]\n",
        "        topk_archs.append(archs[arch_idx])\n",
        "        topk_hxs.append(hxs[arch_idx].detach().requires_grad_(False))\n",
        "        topk_cxs.append(cxs[arch_idx].detach().requires_grad_(False))\n",
        "\n",
        "    return topk_archs, (topk_hxs, topk_cxs)\n",
        "\n",
        "\n",
        "class LinearLrDecay(object):\n",
        "    def __init__(self, optimizer, start_lr, end_lr, decay_start_step, decay_end_step):\n",
        "\n",
        "        assert start_lr > end_lr\n",
        "        self.optimizer = optimizer\n",
        "        self.delta = (start_lr - end_lr) / (decay_end_step - decay_start_step)\n",
        "        self.decay_start_step = decay_start_step\n",
        "        self.decay_end_step = decay_end_step\n",
        "        self.start_lr = start_lr\n",
        "        self.end_lr = end_lr\n",
        "\n",
        "    def step(self, current_step):\n",
        "        if current_step <= self.decay_start_step:\n",
        "            lr = self.start_lr\n",
        "        elif current_step >= self.decay_end_step:\n",
        "            lr = self.end_lr\n",
        "        else:\n",
        "            lr = self.start_lr - self.delta * (current_step - self.decay_start_step)\n",
        "            for param_group in self.optimizer.param_groups:\n",
        "                param_group['lr'] = lr\n",
        "        return lr\n",
        "\n",
        "def load_params(model, new_param, args, mode=\"gpu\"):\n",
        "    if mode == \"cpu\":\n",
        "        for p, new_p in zip(model.parameters(), new_param):\n",
        "            cpu_p = deepcopy(new_p)\n",
        "#             p.data.copy_(cpu_p.cuda().to(f\"cuda:{args.gpu}\"))\n",
        "            p.data.copy_(cpu_p.cuda().to(\"cpu\"))\n",
        "            del cpu_p\n",
        "    \n",
        "    else:\n",
        "        for p, new_p in zip(model.parameters(), new_param):\n",
        "            p.data.copy_(new_p)\n",
        "\n",
        "\n",
        "def copy_params(model, mode='cpu'):\n",
        "    if mode == 'gpu':\n",
        "        flatten = []\n",
        "        for p in model.parameters():\n",
        "            cpu_p = deepcopy(p).cpu()\n",
        "            flatten.append(cpu_p.data)\n",
        "    else:\n",
        "        flatten = deepcopy(list(p.data for p in model.parameters()))\n",
        "    return flatten"
      ],
      "metadata": {
        "id": "3S5qmuFMnL5c"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}